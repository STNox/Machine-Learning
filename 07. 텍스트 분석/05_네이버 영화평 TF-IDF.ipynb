{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 네이버 영화평 감성 분석 - TfidfVectorizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../00. data/NaverMovie/train.tsv', sep='\\t')\n",
    "test_df = pd.read_csv('../00. data/NaverMovie/test.tsv', sep='\\t')"
   ]
  },
  {
   "source": [
    "### Tokenizer 함수 정의"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "def tw_tokenizer(text):\n",
    "    tokens_ko = okt.morphs(text)\n",
    "    return tokens_ko"
   ]
  },
  {
   "source": [
    "### TfidfVectorizer로 변환"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tvector = TfidfVectorizer(tokenizer=tw_tokenizer, ngram_range=(1, 2), max_df=0.9, min_df=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_df=0.9, min_df=3, ngram_range=(1, 2),\n",
       "                tokenizer=<function tw_tokenizer at 0x000001AE1ECEF5E0>)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "tvector.fit(train_df.document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tvect = tvector.transform(train_df['document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tvect = tvector.transform(test_df['document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df.label.values\n",
    "y_test = test_df.label.values"
   ]
  },
  {
   "source": [
    "### LogisticRegression 학습/예측/평가"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8584753546280233"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "lr = LogisticRegression(C=3.5)\n",
    "lr.fit(X_train_tvect, y_train)\n",
    "pred = lr.predict(X_test_tvect)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "source": [
    "### 실제 테스트"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "review1 = '진짜 개노잼이다.. 1편이랑 같은 감독맞나?러닝타임도 길어서 개지루함 ㄹㅇ'\n",
    "review2 = '이런 사랑영화가 다시 나올 수 있을까?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "import re\n",
    "review1 = re.sub(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\", '', review1)\n",
    "review1_tvect = tvector.transform([review1])        # 형태소 분석은 tvector 안에 함수로 수행\n",
    "re_pred = lr.predict(review1_tvect)\n",
    "re_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "review2 = re.sub(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\", '', review2)\n",
    "review2_tvect = tvector.transform([review2])        # 형태소 분석은 tvector 안에 함수로 수행\n",
    "re2_pred = lr.predict(review2_tvect)\n",
    "re2_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = ['진짜 개노잼이다.. 1편이랑 같은 감독맞나?러닝타임도 길어서 개지루함 ㄹㅇ', '이런 사랑영화가 다시 나올 수 있을까?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = list(map(lambda x: re.sub(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\", '', x), reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "review_tvect = tvector.transform(reviews)\n",
    "pred = lr.predict(review_tvect)\n",
    "pred[0], pred[1]"
   ]
  },
  {
   "source": [
    "### 최적 하이퍼 파라미터 탐색"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "stopwords = ['의', '가', '이', '은', '들', '는', '좀', '잘', '걍', '과', '도', '를', '으로', '자', '에', '와', '한', '하다', '을']\n",
    "pipeline = Pipeline([\n",
    "    ('tv', TfidfVectorizer(stop_words=stopwords)),\n",
    "    ('lr', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'tv__ngram_range': [(1, 2), (1, 3)],\n",
    "    'tv__max_df': [700, 1000],\n",
    "    'lr__C': [10, 30]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  9.1min finished\n",
      "{'lr__C': 10, 'tv__max_df': 1000, 'tv__ngram_range': (1, 2)} 0.7957966988617069\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_pipe = GridSearchCV(pipeline, param_grid=params, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_pipe.fit(train_df.document, y_train)\n",
    "print(grid_pipe.best_params_, grid_pipe.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}